{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from stable_baselines3 import PPO, SAC, TD3, DDPG, A2C, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from gym_donkeycar.envs.donkey_env import DonkeyEnv\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, CallbackList\n",
    "\n",
    "import sys\n",
    "\n",
    "from torch.utils.data.dataset import Dataset, random_split\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import gym\n",
    "\n",
    "path = r\"c:\\Users\\spige\\memoire\\gym-donkeycar-retry\\gym-donkeycar\\CarConsumptionModel\"\n",
    "sys.path.insert(0, path)\n",
    "\n",
    "from donkey_environment.ConsumptionWrapper import ConsumptionWrapper\n",
    "from utils.callbacks import CustomProgressBarCallback, SaveObservations\n",
    "from utils.ExpertDataset import ExpertDataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " observation shape : (193563, 120, 160, 3) \n",
      "\n",
      " action shape : (193563, 2) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "expert_dataset = ExpertDataSet()\n",
    "expert_dataset.load_dataset(file_path=\"../data/rollout/dataset_clamped.npz\")\n",
    "\n",
    "print(f\" observation shape : {expert_dataset.observations.shape} \\n\")\n",
    "print(f\" action shape : {expert_dataset.actions.shape} \\n\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_observation(obs: np.ndarray) -> np.ndarray:\n",
    "    # transform (1332, 120, 160, 3) to (1332, 3, 120, 160)\n",
    "    transformed_obs = np.transpose(obs, (0, 3, 1, 2))\n",
    "    return transformed_obs\n",
    "\n",
    "def clamp(x: float, min_value: float, max_value: float) -> float:\n",
    "    return max(min(x, max_value), min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193563, 2)\n"
     ]
    }
   ],
   "source": [
    "print(expert_dataset.actions.shape)\n",
    "\n",
    "clamped_actions = np.ndarray(shape=expert_dataset.actions.shape, dtype=np.float32)\n",
    "for i, action in enumerate(expert_dataset.actions):\n",
    "\n",
    "    steering = action[0]\n",
    "    throttle = action[1]\n",
    "\n",
    "    clamped_steering = clamp(steering, -1.0, 1.0)\n",
    "    clamped_throttle = clamp(throttle, -1.0, 1.0)\n",
    "\n",
    "    clamped_actions[i] = np.array([clamped_steering, clamped_throttle])\n",
    "\n",
    "# store the expert dataset in a new file\n",
    "np.savez(\"../data/rollout/dataset_clamped.npz\", obs=expert_dataset.observations, action=clamped_actions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
